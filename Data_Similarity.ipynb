{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px7lwBfmthJZ"
      },
      "outputs": [],
      "source": [
        "! pip install -q stumpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_pHP-XCjgPd",
        "outputId": "fc787bf7-dea3-4976-86e9-d5c98cc9db93"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image,display\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from time import sleep\n",
        "from os.path import exists\n",
        "from datetime import datetime\n",
        "\n",
        "if not exists('/content/Machine-Learning-For-Manufacturing/Data/o.csv') or not exists('/content/Machine-Learning-For-Manufacturing/Data/pi.csv'):\n",
        "  ! git clone https://github.com/d0c0nn0r/Machine-Learning-For-Manufacturing\n",
        "! chmod ogu+rwx /content/Machine-Learning-For-Manufacturing/data/*.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifQmc0NCFfkO"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "Setup is down, to import the dependency libraries and data sets into the notebook.\n",
        "\n",
        "Pandas is used to handle importing CSV data sets.\n",
        "Plotly is used for all graphing and outputs.\n",
        "Stumpy is used to all Time-series related mathematical calculations, profiling and analysis. \n",
        "\n",
        "## **Load data**\n",
        "\n",
        "Our predefined data sets are hosted in 3 csv files.\n",
        "* o.csv: OPC Data for a specific piece of I/O\n",
        "* pc.csv: Compressed data (i.e. archived values) for the corresponding PI Tag of the OPC Data captured in the previous file.\n",
        "* pi.csv: Interpolated data for the corresponding PI tag of the OPC Data, measured at 1-second intervals.\n",
        "\n",
        "The timestamp field is defined and consolidated across all datasets. Selecting and aligning the OPC and PI Data timestamps is important, as it will be required later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LxVDXYPVkHbT",
        "outputId": "f68588e9-b5b2-48f6-cd5e-e54047cea8d8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import stumpy\n",
        "\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.graph_objs import Scatter, Layout\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "layout = Layout(\n",
        "    paper_bgcolor='rgba(0,0,0,0)',\n",
        "    plot_bgcolor='rgba(0,0,0,0)',\n",
        "    font_family=\"Courier New\",\n",
        "    font_size=12,\n",
        "    font_color=\"#a5b1cd\",\n",
        "    title_font_family=\"Courier New\",\n",
        "    title_font_color=\"black\",\n",
        "    title_font_size=12,\n",
        "    uirevision=True,\n",
        "    autosize=True\n",
        ")\n",
        "\n",
        "o=pd.read_csv('/content/Machine-Learning-For-Manufacturing/Data/o.csv')\n",
        "pc=pd.read_csv('/content/Machine-Learning-For-Manufacturing/Data/pc.csv')\n",
        "pi=pd.read_csv('/content/Machine-Learning-For-Manufacturing/Data/pi.csv')\n",
        "\n",
        "# 13:00 is local time!\n",
        "o['TimeStamp']=pd.to_datetime(o['TimeStamp'].values)\n",
        "#pc.head()\n",
        "pc['TimeStamp']=pd.to_datetime(pc['LocalDateTime'].values)\n",
        "pi['TimeStamp']=pd.to_datetime(pi['TimeStamp'].values)\n",
        "\n",
        "#Filter out non-numeric rows\n",
        "pi = pi[pd.to_numeric(pi.Value, errors='coerce').notnull()]\n",
        "#convert value column to float type\n",
        "pi = pi.astype({'Value':'float64'})\n",
        "\n",
        "pi_shifted = pi.copy()\n",
        "pi_shifted['TimeStamp'] = pi_shifted['TimeStamp'] + timedelta(seconds=30)\n",
        "pi.head()\n",
        "pi_shifted.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9QmRc3ZIBPW"
      },
      "source": [
        "## **Analyzing Signal Similarity**\n",
        "\n",
        "After loading the data, the [MASS Distance Profile](https://stumpy.readthedocs.io/en/latest/api.html#mass) is calculated.\n",
        "This distance measure is computed by measuring the euclidean distance between the OPC data signal, at the Interpolated PI Data. \n",
        "\n",
        "The distance profile is returned as an array of distance measures, at every position in the Dataset arrays (i.e. OPC data and PI data). \n",
        "\n",
        "To account for possible 'client-time-drift' between the OSI-PI Interface capturing values into PI Data Historian, and the OPC Client used to capture our data set, we use this distance profile to find the \"best-fit\" for overlaying the signals on top of each other.\n",
        "\n",
        "Once the \"best-fit\" signal overlay has been found, we now know the exact starting index (i.e. timestamp) where overlaying the Interpolated PI Data and OPC data matches best. \n",
        "This interesting also allows us to measure the 'clock-drift' between our OPC Client and the PI Interface as they acquire/read/poll/advise data from a source.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAa9MaONvYC6"
      },
      "outputs": [],
      "source": [
        "# need to resample\n",
        "# DOC: DON'T resample, use interpolated data set\n",
        "if o.index.name!='TimeStamp':\n",
        "  o.set_index('TimeStamp',inplace=True)\n",
        "  pc.set_index('TimeStamp',inplace=True)\n",
        "  pi.set_index('TimeStamp',inplace=True)\n",
        "\n",
        "# Resample OPC Data, as we expect a value at every single second\n",
        "# In can occur than data does not occur every second, so\n",
        "# we re-sample\n",
        "o=o.resample('1S').interpolate(method='linear')\n",
        "\n",
        "# Resample also for COMPRESSED data, to get a\n",
        "# panda's \"interpolated\" value at every 1 second\n",
        "pc=pc.resample('1S').interpolate(method='linear')\n",
        "\n",
        "# alignment using stumpy\n",
        "# DISTANCE using PI INTERPOLATED VALUES\n",
        "distance_profile = stumpy.mass(o['Value'].values,\n",
        "                               pi['Value'].values,\n",
        "                               normalize=False\n",
        "                               )\n",
        "index_min = min(range(len(distance_profile)), key=distance_profile.__getitem__)\n",
        "\n",
        "#DISTANCE using PANDAS INTERPOLATED VALUES\n",
        "distance_profile2 = stumpy.mass(o['Value'].values,\n",
        "                               pc['Value'].values,\n",
        "                               normalize=False\n",
        "                               )\n",
        "index_min2 = min(range(len(distance_profile2)), key=distance_profile2.__getitem__)\n",
        "\n",
        "#DISTANCE using time-shifted dataframe\n",
        "distance_profile3 = stumpy.mass(o['Value'].values,\n",
        "                               pi_shifted['Value'].values,\n",
        "                               normalize=False\n",
        "                               )\n",
        "index_min3 = min(range(len(distance_profile3)), key=distance_profile3.__getitem__)\n",
        "\n",
        "n=len(o['Value'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqvIEqOyD3pB"
      },
      "source": [
        "## **Visualizing Signal Similarity: Using Interpolated Data**\n",
        "\n",
        "Next, we want to create 3 graphs to illustrate our data.\n",
        "\n",
        "### **Graph #1: Original Data**\n",
        "\n",
        "We print 2 signals. \n",
        "* The \"pi interpolated\" represents the Interpolated Data from the PI Data Historian.\n",
        "* The \"opc\" represents the OPC Data received from the underlying device or PLC, through the OPC Server.\n",
        "\n",
        "### **Graph #2: Distance Profile**\n",
        "\n",
        "We print the distance profile, which measures the similarity of the signals over the entire time period.\n",
        "The closer to 0 the value is, the more similar the signals are at that point in time. i.e. 0=100% matching.\n",
        "This graph does not \"line-up\" perfectly with Graph #1.\n",
        "\n",
        "### **Graph #3: Time-Aligned Overlay**\n",
        "\n",
        "We print the re-aligned PI Interpolated data and OPC Data sets.\n",
        "On this graph, the signals are overlayed on-top of each other, for the 'best-fit' time period. The best-fit time period is that which was measured by the Graph #2, Distance Profile.\n",
        "\n",
        "## **Statistics**\n",
        "\n",
        "### Max Error\n",
        "\n",
        "Max error computes the maximum residual error between 2 data sets: the PI Interpolated data set, and the OPC data set.\n",
        "The value returned is the maximum difference between 2 corresponding values at the same index in the data sets.\n",
        "For more detail, see (sklean.metrics documentation)[https://scikit-learn.org/stable/modules/model_evaluation.html#max-error]\n",
        "\n",
        "### Explained Variance Score\n",
        "\n",
        "The explained variance is used to measure the proportion of the variability of the 2 data sets.\n",
        "The closer this value is to 100%, to more accurate the 2 data sets are.\n",
        "For more detail, see (sklean.metrics documentation)[https://scikit-learn.org/stable/modules/model_evaluation.html#explained-variance-score]\n",
        "\n",
        "### Mean Absolute Error\n",
        "\n",
        "This refers to the magnitude of difference between the prediction of an observation and the true value of that observation. MAE takes the average of absolute errors for a group of predictions and observations as a measurement of the magnitude of errors for the entire group. MAE can also be referred as L1 loss function.\n",
        "\n",
        "For more detail, see (sklean.metrics documentation)[https://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error]\n",
        "\n",
        "### Mean Squared Error\n",
        "\n",
        "The Mean Squared Error measures how close a regression line is to a set of data points. It is a risk function corresponding to the expected value of the squared error loss. A larger MSE indicates that the data points are dispersed widely around its central moment (mean), whereas a smaller MSE suggests the opposite. A smaller MSE is preferred because it indicates that your data points are dispersed closely around its central moment (mean).\n",
        "For more detail, see (sklean.metrics documentation)[https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error]\n",
        "\n",
        "### Median Absolute Error\n",
        "\n",
        "The median_absolute_error is particularly interesting because it is robust to outliers. The loss is calculated by taking the median of all absolute differences between the target and the prediction.\n",
        "\n",
        "For more detail, see (sklean.metrics documentation)[https://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "av8R6_DwmI9E",
        "outputId": "3f77e48d-20cb-445d-fd8d-caba004b9f20"
      },
      "outputs": [],
      "source": [
        "# raw, similarity, aligned\n",
        "fig = make_subplots(rows=3, cols=1, shared_xaxes=False)\n",
        "fig.update_layout(layout)\n",
        "\n",
        "fig.add_trace(go.Scatter(x=pi.index,y=pi['Value'], name='pi interpolated'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=o.index,y=o['Value'], name='opc'),row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(y=distance_profile, name='distance_profile'),row=2, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(y=o['Value'].values, name='opc-aligned'),row=3, col=1)\n",
        "fig.add_trace(go.Scatter(y=pi['Value'].values[index_min:index_min+n], name='pi int.-aligned'),row=3, col=1)\n",
        "fig.show()\n",
        "\n",
        "# some metrics\n",
        "from sklearn.metrics import *\n",
        "\n",
        "y_true=o['Value'].values\n",
        "y_pred=pi['Value'].values[index_min:index_min+n]\n",
        "first_opc_ts=o.iloc[0].name\n",
        "matched_pic_ts=pi.iloc[index_min].name\n",
        "\n",
        "print('max_error: ',max_error(y_true, y_pred))\n",
        "print('explained_variance_score: {:.3%}'.format(explained_variance_score(y_true, y_pred)))\n",
        "print('mean_absolute_error: ',mean_absolute_error(y_true, y_pred))\n",
        "print('mean_squared_error: ',mean_squared_error(y_true, y_pred))\n",
        "print('median_absolute_error ',median_absolute_error(y_true, y_pred))\n",
        "print('OPC Signal Start Time: ', first_opc_ts.strftime(\"%d-%b-%y %H:%M:%S.%f\"))\n",
        "print('PI Signal Start Time: ', matched_pic_ts.strftime(\"%d-%b-%y %H:%M:%S.%f\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Time shifted\n",
        "\n",
        "Let's see output using the time-shifted data set\n",
        "This should showcase how clock-drift is managed by the functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# raw, similarity, aligned\n",
        "fig = make_subplots(rows=3, cols=1, shared_xaxes=False)\n",
        "fig.update_layout(layout)\n",
        "\n",
        "fig.add_trace(go.Scatter(x=pi_shifted.index,y=pi_shifted['Value'], name='pi interpolated'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=o.index,y=o['Value'], name='opc'),row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(y=distance_profile3, name='distance_profile'),row=2, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(y=o['Value'].values, name='opc-aligned'),row=3, col=1)\n",
        "fig.add_trace(go.Scatter(y=pi_shifted['Value'].values[index_min3:index_min3+n], name='pi int.-aligned'),row=3, col=1)\n",
        "fig.show()\n",
        "\n",
        "# some metrics\n",
        "from sklearn.metrics import *\n",
        "\n",
        "y_true          = o['Value'].values\n",
        "y_pred          = pi_shifted['Value'].values[index_min3:index_min3+n]\n",
        "first_opc_ts    = o.iloc[0].name\n",
        "matched_pic_ts  = pi_shifted.iloc[index_min3].name\n",
        "\n",
        "print('max_error: ',max_error(y_true, y_pred))\n",
        "print('explained_variance_score: {:.3%}'.format(explained_variance_score(y_true, y_pred)))\n",
        "print('mean_absolute_error: ',mean_absolute_error(y_true, y_pred))\n",
        "print('mean_squared_error: ',mean_squared_error(y_true, y_pred))\n",
        "print('median_absolute_error ',median_absolute_error(y_true, y_pred))\n",
        "print('OPC Signal Start Time: ', first_opc_ts.strftime(\"%d-%b-%y %H:%M:%S.%f\"))\n",
        "print('PI Signal Start Time: ', matched_pic_ts.strftime(\"%d-%b-%y %H:%M:%S.%f\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "history_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.9 64-bit (windows store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "1c6b4543b58d7fccc206099aca52a23523521d459cbe486d12738393ec9f990e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
